# Augmented Meta-Transfer Learning(A-MTL)
 for few shot image classification
## Datasets

Directly download processed images: [\[Download Page\]](https://mtl.yyliu.net/download/)

### ğ’ğ’Šğ’ğ’ŠImageNet

The ğ‘šğ‘–ğ‘›ğ‘–ImageNet dataset was proposed by [Vinyals et al.](http://papers.nips.cc/paper/6385-matching-networks-for-one-shot-learning.pdf) for few-shot learning evaluation. Its complexity is high due to the use of ImageNet images but requires fewer resources and infrastructure than running on the full [ImageNet dataset](https://arxiv.org/pdf/1409.0575.pdf). In total, there are 100 classes with 600 samples of 84Ã—84 color images per class. These 100 classes are divided into 64, 16, and 20 classes respectively for sampling tasks for meta-training, meta-validation, and meta-test. To generate this dataset from ImageNet, you may use the repository [ğ‘šğ‘–ğ‘›ğ‘–ImageNet tools](https://github.com/y2l/mini-imagenet-tools).

### Fewshot-CIFAR100

Fewshot-CIFAR100 (FC100) is based on the popular object classification dataset CIFAR100. The splits were
proposed by [TADAM](https://arxiv.org/pdf/1805.10123.pdf). It offers a more challenging scenario with lower image resolution and more challenging meta-training/test splits that are separated according to object super-classes. It contains 100 object classes and each class has 600 samples of 32 Ã— 32 color images. The 100 classes belong to 20 super-classes. Meta-training data are from 60 classes belonging to 12 super-classes. Meta-validation and meta-test sets contain 20 classes belonging to 4 super-classes, respectively.


## Performance
### MTL performance
| backbone | Aug method |mini 1-shot | mini 5-shot | FC100 1-shot | FC100 5-shot |
| ----  | ----       |----        | ----        | ----         | ----         |  
| ResNet12| None     | 0.5328 + 0.0080| 0.6857 + 0.0070 | 0.3922 + 0.0071 | 0.5153 + 0.0070 | 
|         | Transport| 0.5342 + 0.0085 | 0.6903 + 0.0070 | 0.4007+0.0079 | 0.5119 + 0.0071
| ResNet18| None     | 0.4632 + 0.0077| 0.6618 + 0.0069 | 0.3749 + 0.0078 | 0.5224 + 0.0071|
| |Transport | 0.4734 + 0.0074 | 0.6597 + 0.0069 | 0.3804 + 0.0069 | 0.5256+0.0069 |

## MAML
see README of `maml`
## Meta-Transfer Learning
To reproduce the result of experiment, do the following command

`cd /meta-transfer-learning`
### pre_train command
- pre_train(ResNet12, MiniImageNet)
  
`python main.py --phase pre_train --model_type ResNet --dataset MiniImageNet --dataset_dir ../data/mini-imagenet --pre_batch_size 100 --pre_lr 0.1 --gpu xxx`
- pre_train(ResNet18, MiniImageNet)
  
`python main.py --phase pre_train --model_type ResNet18 --dataset MiniImageNet --dataset_dir ../data/mini-imagenet --pre_batch_size 64 --pre_lr 0.01 --gpu xxx`


### meta_train command
- meta_train(ResNet12, MiniImageNet, 1 shot)

`python main.py --phase meta_train --dataset MiniImageNet --dataset_dir ../data/mini-imagenet/ --shot 1 --model_type ResNet --pre_batch_size 128 --pre_lr 0.1 --gpu xxx`

- meta_train(ResNet12, FC100, 1 shot)

`python main.py --phase meta_train --dataset FC100 --dataset_dir ../data/fc100/ --shot 1 --model_type ResNet  --pre_batch_size 128 --pre_lr 0.1  --gpu xxx`

### meta_eval command
- meta_eval(ResNet12, MiniImageNet, 5 shot)

`python main.py  --phase meta_train --dataset MiniImageNet --dataset_dir ../data/mini-imagenet/ --shot 5 --model_type ResNet  --pre_batch_size 128 --pre_lr 0.1 --gpu xxx`

- meta_eval(ResNet12, FC100, 5 shot)

`python main.py  --phase meta_train --dataset FC100 --dataset_dir ../data/fc100/ --shot 5 --model_type ResNet --pre_batch_size 128 --pre_lr 0.1 --gpu xxx`

- éœ€è¦æ³¨æ„çš„åœ°æ–¹ï¼š
    1. `--gpu`éœ€è¦æ ¹æ®è‡ªå·±æ˜¾å¡çš„æƒ…å†µæ¥è®¾ç½®ï¼Œä¸€èˆ¬è®¾ç½®ä¸º0
    2. å¦‚æœè¦è·‘Resnet18åªéœ€å°†`--model_type ResNet`æ”¹ä¸º`--model_type ResNet18`
    3. å¦‚æœè¦è®­ç»ƒFC100æ•°æ®é›†åªéœ€è®¾ç½®`--dataset FC100` `dataset_dir ../data/fc100`
    4. `--dataset_dir` éœ€è¦æ ¹æ®å®é™…æƒ…å†µé€‰æ‹©æ•°æ®é›†çš„è·¯å¾„
    5. ä¸€ä¸ªæ¨¡å‹çš„pre_train å¤§æ¦‚éœ€è¦4-5h, meta_train å¤§æ¦‚éœ€è¦1-2å°æ—¶
    6. å¯¹äºæˆ‘ä»¬çš„A-MTLæ–¹æ³•ï¼Œåªéœ€åœ¨meta_train å’Œmeta_eval é˜¶æ®µåŠ å…¥`--augment 1`å³å¯